{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **What is Topic Modeling?**\n",
        "Topic modeling is an unsupervised machine learning technique used to identify and extract topics or themes from a collection of unstructured text data. It automatically groups similar words, phrases, or sentences into clusters that represent different underlying topics in the text corpus.\n",
        "\n",
        "Some common algorithms for topic modeling include:\n",
        "\n",
        "* Latent Dirichlet Allocation (LDA): A probabilistic model that assumes each document is a mixture of topics and each topic is a mixture of words.\n",
        "\n",
        "* Non-Negative Matrix Factorization (NMF): A linear algebra-based method that decomposes text into parts corresponding to topics.\n",
        "\n",
        "* Latent Semantic Analysis (LSA): A singular value decomposition-based method used for text similarity and topic extraction."
      ],
      "metadata": {
        "id": "gEKwb6bMSERk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **When and Where Do We Use Topic Modeling?**\n",
        "Topic modeling is useful in any scenario where large volumes of unstructured text data need to be understood or analyzed. Some common applications include:\n",
        "\n",
        "1. **Content Organization and Summarization\n",
        "Use Case:** Automatically organizing articles, reports, or documents by their topics for easier navigation.\n",
        "Example: Summarizing customer reviews to highlight common themes.\n",
        "2. **Search Engine Optimization (SEO)\n",
        "Use Case:** Improving the relevance of search results by identifying content topics.\n",
        "Example: Google’s algorithms for categorizing and ranking web pages.\n",
        "3. **Customer Feedback Analysis\n",
        "Use Case:** Analyzing feedback from surveys, social media, or reviews to understand customer sentiment and issues.\n",
        "Example: Analyzing online reviews to discover common product complaints.\n",
        "4. **Content Recommendation Systems\n",
        "Use Case:** Suggesting articles, movies, or products based on user preferences.\n",
        "Example: Netflix using topic modeling to recommend shows based on viewing history.\n",
        "5. **Academic and Legal Research\n",
        "Use Case:** Extracting and summarizing key topics from large bodies of literature or legal documents.\n",
        "Example: Identifying themes in historical archives or research papers.\n",
        "6. **Market Research\n",
        "Use Case:** Understanding public discussions about brands, products, or competitors by analyzing social media or news articles.\n",
        "Example: Monitoring Twitter conversations to track trends and sentiments.\n",
        "7. **Healthcare and Medical Research\n",
        "Use Case:** Extracting topics from medical research papers or clinical notes.\n",
        "Example: Identifying common side effects from patient reports.\n",
        "8. **Political Analysis\n",
        "Use Case:** Analyzing speeches, debates, or social media to understand political sentiment and key issues.\n",
        "Example: Discovering election topics discussed by voters on social media.\n"
      ],
      "metadata": {
        "id": "pt3ZlLHDSQOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advantages**\n",
        "* Provides a high-level overview of large text datasets.\n",
        "* Helps identify hidden patterns in unstructured data.\n",
        "* Facilitates decision-making by uncovering actionable insights.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* Results may not always align with human interpretation due to subjectivity in language.\n",
        "* Requires large datasets for reliable output.\n",
        "* Needs proper pre-processing, like removing stop words and stemming."
      ],
      "metadata": {
        "id": "vwwl3zkeS7Se"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt0SgrVZJSx9",
        "outputId": "76edecf8-1390-4383-eb3f-7ff4a2d1f590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Z9CMx1JniI",
        "outputId": "fe1871e4-b559-4adb-92c0-c2df9d7eea8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Load Your Data**\n",
        "A dataset containing the text we want to analyze."
      ],
      "metadata": {
        "id": "BhyQFP9jNfzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"Dogs are loyal and friendly animals.\",\n",
        "    \"I love programming in Python.\",\n",
        "    \"Artificial intelligence is the future of technology.\",\n",
        "    \"Cats and dogs are common pets.\",\n",
        "    \"Natural language processing is a branch of AI.\"\n",
        "]"
      ],
      "metadata": {
        "id": "HIcjzXm2MXEC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preprocess the Text Data**\n",
        "Preprocessing involves tokenizing, removing stop words, and other cleaning steps."
      ],
      "metadata": {
        "id": "_U9Y4_bhMnWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(doc):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(doc.lower())  # Tokenize and convert to lowercase\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]  # Remove non-alphabetic tokens and stop words\n",
        "    return tokens\n",
        "\n",
        "# Preprocess each document\n",
        "processed_docs = [preprocess_text(doc) for doc in documents]"
      ],
      "metadata": {
        "id": "2BcR_g4-Mldb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Create a Dictionary and Corpus**\n",
        "\n",
        "A dictionary maps each word to a unique ID, and the corpus represents the documents in a bag-of-words format."
      ],
      "metadata": {
        "id": "9IllyuayN9AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary and filter out extreme words\n",
        "dictionary = corpora.Dictionary(processed_docs)\n",
        "dictionary.filter_extremes(no_below=1, no_above=0.5)\n",
        "\n",
        "# Create a corpus\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
      ],
      "metadata": {
        "id": "kHVEaR2oNBsD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Build the LDA Model**\n",
        "\n",
        "The LDA model identifies latent topics in the text."
      ],
      "metadata": {
        "id": "nNgaya4zOI6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LDA model\n",
        "num_topics = 2  # Specify the number of topics\n",
        "lda_model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=10, random_state=42)\n",
        "\n",
        "# Print the topics\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Topic {idx}: {topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpf1YIIoOGZ-",
        "outputId": "059e09a1-5643-42d0-a142-3f8c922ab043"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: 0.113*\"dogs\" + 0.068*\"friendly\" + 0.068*\"common\" + 0.068*\"cats\" + 0.068*\"loyal\" + 0.068*\"pets\" + 0.068*\"animals\" + 0.068*\"cat\" + 0.068*\"mat\" + 0.068*\"sat\"\n",
            "Topic 1: 0.065*\"language\" + 0.065*\"branch\" + 0.065*\"processing\" + 0.065*\"ai\" + 0.065*\"natural\" + 0.065*\"technology\" + 0.065*\"artificial\" + 0.065*\"future\" + 0.065*\"intelligence\" + 0.065*\"python\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Visualize the Topics**\n",
        "\n",
        "We will use pyLDAvis for an interactive visualization.\n",
        "[PyLDAvis is a Python library used for interactive visualization of topic models created with algorithms like Latent Dirichlet Allocation (LDA). It is particularly helpful for understanding and interpreting the topics generated by an LDA model, as it provides a visual interface that allows users to explore topics and their relationships to words and documents.\n",
        "\n",
        "* Visualizes topics as circles in a 2D plane using Multidimensional Scaling (MDS). The size of the circle represents the importance of the topic.\n",
        "\n",
        "* Displays the most relevant terms for a selected topic and their contribution.]"
      ],
      "metadata": {
        "id": "vX-eW9K8OXsr"
      }
    },
    {
      "source": [
        "!pip install pyLDAvis==3.3.1 # Install a version of pyLDAvis which is known to work.\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(vis) # Display the vis object directly within the notebook"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MEaYdkV3QQIw",
        "outputId": "02ea7c4c-1b1f-4379-9de4-d7717a11e86b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis==3.3.1\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (2.10.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (1.0.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis==3.3.1) (2.0)\n",
            "Collecting sklearn (from pyLDAvis==3.3.1)\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el23471331124736519042830428739\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el23471331124736519042830428739_data = {\"mdsDat\": {\"x\": [0.06689424049381681, -0.06689424049381681], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [52.05591274577218, 47.94408725422782]}, \"tinfo\": {\"Term\": [\"dogs\", \"friendly\", \"common\", \"cats\", \"loyal\", \"pets\", \"animals\", \"cat\", \"mat\", \"sat\", \"language\", \"branch\", \"processing\", \"ai\", \"natural\", \"technology\", \"artificial\", \"future\", \"intelligence\", \"python\", \"love\", \"programming\", \"language\", \"branch\", \"processing\", \"ai\", \"natural\", \"technology\", \"artificial\", \"future\", \"intelligence\", \"python\", \"love\", \"programming\", \"sat\", \"mat\", \"cat\", \"animals\", \"pets\", \"loyal\", \"cats\", \"common\", \"friendly\", \"dogs\", \"dogs\", \"friendly\", \"common\", \"cats\", \"loyal\", \"pets\", \"animals\", \"cat\", \"mat\", \"sat\", \"programming\", \"love\", \"python\", \"intelligence\", \"future\", \"artificial\", \"technology\", \"natural\", \"ai\", \"processing\", \"branch\", \"language\"], \"Freq\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.778439417887808, 0.7783058783677042, 0.7782890186687732, 0.7782383503672241, 0.7781805456851751, 0.7769929627652401, 0.7768544277787863, 0.7768406010415678, 0.7767075075452452, 0.7763312418833894, 0.7761539028279676, 0.7760884265368813, 0.2662095614485762, 0.26605619617139614, 0.265567755528558, 0.2639374717045512, 0.26389666052856753, 0.26388941264212235, 0.26384581381750594, 0.2638333474528202, 0.2637722644959791, 0.26442979275428613, 1.248487586021075, 0.7481852906873244, 0.7481265472923879, 0.7481144699790234, 0.7480725690959219, 0.748065585615405, 0.7480263959659159, 0.7464583170347873, 0.7459886163510787, 0.7458410595156859, 0.2554653298644684, 0.25540243746051894, 0.25523181459977173, 0.2548700497693467, 0.2547420056001041, 0.25472873698712195, 0.2545954552074917, 0.2534533480482466, 0.2533977677591913, 0.2533490682524101, 0.2533328830093297, 0.253204407507467], \"Total\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.031643825395275, 1.031638761377034, 1.0316380869211832, 1.0316361181264155, 1.0316338937334217, 1.0315884179727317, 1.0315831647659084, 1.031582606641672, 1.0315775573145918, 1.031563056483161, 1.0315563402884864, 1.0315537564013497, 1.0120506209642621, 1.0120448125224748, 1.0120260725633452, 1.0119638676704672, 1.0119622461439726, 1.0119619817380443, 1.0119602837965294, 1.0119598947452082, 1.0119575551833035, 1.5129173787753611, 1.5129173787753611, 1.0119575551833035, 1.0119598947452082, 1.0119602837965294, 1.0119619817380443, 1.0119622461439726, 1.0119638676704672, 1.0120260725633452, 1.0120448125224748, 1.0120506209642621, 1.0315537564013497, 1.0315563402884864, 1.031563056483161, 1.0315775573145918, 1.031582606641672, 1.0315831647659084, 1.0315884179727317, 1.0316338937334217, 1.0316361181264155, 1.0316380869211832, 1.031638761377034, 1.031643825395275], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.7331, -2.7333, -2.7333, -2.7334, -2.7334, -2.735, -2.7351, -2.7352, -2.7353, -2.7358, -2.736, -2.7361, -3.8061, -3.8067, -3.8085, -3.8147, -3.8148, -3.8149, -3.815, -3.8151, -3.8153, -3.8128, -2.1784, -2.6905, -2.6905, -2.6906, -2.6906, -2.6906, -2.6907, -2.6928, -2.6934, -2.6936, -3.765, -3.7653, -3.7659, -3.7674, -3.7679, -3.7679, -3.7684, -3.7729, -3.7732, -3.7733, -3.7734, -3.7739], \"loglift\": [22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3712, 0.3711, 0.371, 0.371, 0.3709, 0.3694, 0.3693, 0.3692, 0.3691, 0.3686, 0.3684, 0.3683, -0.6826, -0.6832, -0.685, -0.6911, -0.6912, -0.6913, -0.6914, -0.6915, -0.6917, -1.0914, 0.543, 0.4331, 0.4331, 0.433, 0.433, 0.433, 0.4329, 0.4308, 0.4301, 0.4299, -0.6606, -0.6608, -0.6615, -0.663, -0.6635, -0.6635, -0.664, -0.6686, -0.6688, -0.669, -0.6691, -0.6696]}, \"token.table\": {\"Topic\": [1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1], \"Freq\": [0.9693340339965308, 0.9881775742665517, 0.969383791976602, 0.9693315503822264, 0.9881168352383605, 0.9881810739136337, 0.9881814538231088, 0.6609746269220962, 0.9881837384166399, 0.9693843164489856, 0.9693890613549265, 0.9693267922355365, 0.9694089997259274, 0.988179415873411, 0.9880985383518209, 0.9693361240595338, 0.9881791576814708, 0.9693321841038229, 0.9694114279497879, 0.9694026881974943, 0.9880928673777399, 0.9693788555373576], \"Term\": [\"ai\", \"animals\", \"artificial\", \"branch\", \"cat\", \"cats\", \"common\", \"dogs\", \"friendly\", \"future\", \"intelligence\", \"language\", \"love\", \"loyal\", \"mat\", \"natural\", \"pets\", \"processing\", \"programming\", \"python\", \"sat\", \"technology\"]}, \"R\": 22, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el23471331124736519042830428739\", ldavis_el23471331124736519042830428739_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el23471331124736519042830428739\", ldavis_el23471331124736519042830428739_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el23471331124736519042830428739\", ldavis_el23471331124736519042830428739_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Assign Topics to Documents**\n",
        "We can infer the dominant topic for each document."
      ],
      "metadata": {
        "id": "_33e6V1kRO-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_document_topics(corpus, lda_model):\n",
        "    topics = []\n",
        "    for bow in corpus:\n",
        "        topic_scores = lda_model.get_document_topics(bow)\n",
        "        dominant_topic = sorted(topic_scores, key=lambda x: x[1], reverse=True)[0]\n",
        "        topics.append(dominant_topic)\n",
        "    return topics\n",
        "\n",
        "# Get topics for each document\n",
        "document_topics = get_document_topics(corpus, lda_model)\n",
        "print(document_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Q_NURmQCtF",
        "outputId": "6b30dbe4-5fb0-4995-d62e-9e306b723ccf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.86966133), (0, 0.8963828), (1, 0.8691533), (1, 0.8953342), (0, 0.8963873), (1, 0.9128408)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "The conclusion of this tutorial is that topic modeling is a robust and efficient technique for uncovering hidden themes in text data. By following the steps provided, you can preprocess your data, build an LDA model, and extract meaningful insights such as dominant topics and their relevance to each document\n"
      ],
      "metadata": {
        "id": "hFnA5hIJTVfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mub0TnVRnVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}